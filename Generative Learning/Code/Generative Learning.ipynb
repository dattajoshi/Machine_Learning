{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>CS584 Assignment II : Generative Learning</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from sklearn.cross_validation import KFold \n",
    "from collections import defaultdict\n",
    "from sys import float_info\n",
    "from sys import maxint\n",
    "import math as math\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import Binarizer \n",
    "from random import randint\n",
    "import random as rd\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(X_data,Y_data,plot_type='bo',X_name='X-axis',Y_name='Y-axis',multi_plot='N',X2_data='N',Y2_data='N',plot2_type='N'):\n",
    "    '''Plot data on to screen'''\n",
    "    fig = mpl.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(X_name)    \n",
    "    ax.set_ylabel(Y_name)           \n",
    "    ax.plot(X_data,Y_data,plot_type)\n",
    "    if multi_plot == 'Y':        \n",
    "        ax.plot(X2_data,Y2_data,plot2_type)\n",
    "    mpl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels(data_matrix):\n",
    "    '''Segregate the features and labels , and return them\n",
    "    '''\n",
    "    return data_matrix[:,:len(data_matrix[0])-1],data_matrix[:,len(data_matrix[0])-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_j(data_matrix):\n",
    "    '''\n",
    "    Computes the mean vector for every different class in the data matrix\n",
    "    '''    \n",
    "    mu_j = defaultdict(lambda : np.zeros(len(data_matrix[0])-1))    \n",
    "    j_count = defaultdict(lambda : 0)\n",
    "    \n",
    "    for row in data_matrix:\n",
    "        \n",
    "        lbl      = row[len(row)-1]\n",
    "        feat_vec = row[0:len(row)-1]\n",
    "        \n",
    "        mu_j[lbl] += feat_vec\n",
    "        \n",
    "        j_count[lbl] += 1\n",
    "    \n",
    "    for lbl in mu_j.keys():\n",
    "        mu_j[lbl] /= j_count[lbl]\n",
    "    \n",
    "    return mu_j,j_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_params(data_matrix):\n",
    "    '''\n",
    "    Computes the Co-variance matrix all the different class labels in the training dataset.    \n",
    "    '''\n",
    "    j_SigmaJ,j_Mj = mu_j(data_matrix)\n",
    "    \n",
    "    feature_matrix,labels= get_features_labels(data_matrix)\n",
    "    \n",
    "    no_of_features = len(feature_matrix[0])\n",
    "    \n",
    "    cov_j = defaultdict(lambda : np.zeros((no_of_features,no_of_features)))\n",
    "    \n",
    "    lbl_and_cnt = defaultdict(lambda : 0)\n",
    "    \n",
    "    for _id,label in enumerate(labels):        \n",
    "        X_minus_mu_j = feature_matrix[_id] - j_SigmaJ[label[0]]\n",
    "        cov_j[label[0]] += np.outer(X_minus_mu_j,np.transpose(X_minus_mu_j)) \n",
    "    \n",
    "    for j in cov_j.iterkeys():\n",
    "        cov_j[j] /= float(j_Mj[j])\n",
    "    \n",
    "    return {'cov' : cov_j, 'mean' : j_SigmaJ, 'count' : j_Mj}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def membership_j(j,mu_j,cov_j,X,alpha_j):\n",
    "    '''\n",
    "    Computes the the membership value for class j of a given feature vector X.\n",
    "    '''\n",
    "    g_of_x = 0.0\n",
    "    \n",
    "    det = np.linalg.det(cov_j)    \n",
    "    det = math.pow(det,0.5)\n",
    "    \n",
    "    g_of_x += (-1.0 * math.log(det))    \n",
    "    g_of_x += math.log(alpha_j)\n",
    "    \n",
    "    x_minus_j = X - mu_j\n",
    "    \n",
    "    trans_x = np.transpose(x_minus_j)\n",
    "    cov_inv = np.linalg.inv(cov_j)\n",
    "    \n",
    "\n",
    "    g_of_x += (-0.5 * np.dot(np.dot(x_minus_j,cov_inv),trans_x))\n",
    "    \n",
    "    return g_of_x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_zero(x):\n",
    "    '''\n",
    "    To avoid divide by zero errors.\n",
    "    '''\n",
    "    if x == 0 :\n",
    "        return 1\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_performance(conf_matrix):\n",
    "    '''\n",
    "    For a confusion matrix, compute accuracy, precison, recall and F-Measure.\n",
    "    '''    \n",
    "    measure_and_value = defaultdict(lambda : defaultdict(lambda : 0.0) )\n",
    "    \n",
    "    #Accuracy\n",
    "    measure_and_value['acc'] = float(conf_matrix.trace())/replace_zero(np.sum(conf_matrix))\n",
    "    \n",
    "    #Precision\n",
    "    for r_num,row in enumerate(conf_matrix):\n",
    "        measure_and_value['prec'][r_num+1] = conf_matrix[r_num,r_num] / replace_zero(sum(row))\n",
    "    \n",
    "    \n",
    "    conf_mat_trans = np.transpose(conf_matrix)\n",
    "    \n",
    "    #Recall\n",
    "    for r_num,row in enumerate(conf_mat_trans):\n",
    "        measure_and_value['rec'][r_num+1] = conf_mat_trans[r_num,r_num] / replace_zero(sum(row))\n",
    "    \n",
    "    #F-Measure\n",
    "    for j in measure_and_value['rec'].keys():\n",
    "        nr = 2 * measure_and_value['prec'][j] * measure_and_value['rec'][j]\n",
    "        dr = measure_and_value['prec'][j] + measure_and_value['rec'][j]\n",
    "        \n",
    "        measure_and_value['F-Measure'][j] = float(nr) / replace_zero(dr)\n",
    "            \n",
    "    return measure_and_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def K_fold(K,data_matrix,PR_Curve='N',tow=1):\n",
    "    '''\n",
    "    Perform K-Fold cross validation on the data_matrix,return the accuracy.\n",
    "    '''    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    kf = KFold(len(data_matrix),K)     \n",
    "    \n",
    "    f = open('workfile.txt','a')\n",
    "    \n",
    "    train_data = []\n",
    "    test_data  = []\n",
    "    \n",
    "    #create the confusion_matrix.\n",
    "    k = len(get_params(data_matrix)['mean'].keys()) # No of different classes    \n",
    "    conf_matrix = np.zeros((k,k))    \n",
    "    \n",
    " \n",
    "    pr_details = defaultdict(lambda : defaultdict(lambda : [])) \n",
    "        \n",
    "    for tr_row_num,tst_row_num in kf:           \n",
    "        \n",
    "        if PR_Curve == 'Y':\n",
    "            pr_details = defaultdict(lambda : defaultdict(lambda : [])) \n",
    "            \n",
    "        train_data = []\n",
    "        test_data  = []\n",
    "                \n",
    "        \n",
    "        train_data.append(data_matrix[tr_row_num])\n",
    "        test_data.append(data_matrix[tst_row_num])\n",
    "        \n",
    "        train_data = np.array(train_data[0])\n",
    "        test_data = np.array(test_data[0])\n",
    "\n",
    "        #Compute the parameters for the train data.\n",
    "        dicts = get_params(train_data)\n",
    "        #dicts = get_params(train_data)\n",
    "\n",
    "        X_test = test_data[:,:len(test_data[0])-1]    \n",
    "\n",
    "        for _id,feat_vector in enumerate(X_test):\n",
    "\n",
    "            prev_mem = -maxint-1\n",
    "            best_class = -1\n",
    "\n",
    "            for class_id in dicts['mean'].keys():\n",
    "                mean = dicts['mean'][class_id]\n",
    "                cov = dicts['cov'][class_id]\n",
    "\n",
    "                alpha_j = float(dicts['count'][class_id])/ sum(dicts['count'].values())\n",
    "\n",
    "                membership_value = membership_j(class_id,mean,cov,feat_vector,alpha_j)\n",
    "\n",
    "                if membership_value > prev_mem:\n",
    "                    prev_mem = membership_value\n",
    "                    best_class = class_id        \n",
    "            \n",
    "            actual_cls = test_data[:,len(test_data[0])-1:][_id][0]            \n",
    "            conf_matrix[best_class-1,actual_cls-1] +=1       \n",
    "            \n",
    "            #To Plot Prec-Recall Curve.\n",
    "                      \n",
    "            for class_id in dicts['mean'].keys():\n",
    "                measure_and_value = evaluate_performance(conf_matrix) \n",
    "                pr_details[class_id]['prec'].append(measure_and_value['prec'][class_id])\n",
    "                pr_details[class_id]['rec'].append(measure_and_value['rec'][class_id])\n",
    "\n",
    "                \n",
    "            if _id % 100 == 0:\n",
    "                f.write(str(conf_matrix) + '\\n')\n",
    "                f.write('\\n')\n",
    "    \n",
    "    if PR_Curve == 'Y':    \n",
    "        for k in pr_details.keys():\n",
    "            Y_data = pr_details[k]['prec']\n",
    "            X_data = pr_details[k]['rec']\n",
    "            \n",
    "        plot_x = []\n",
    "        plot_y = []\n",
    "        \n",
    "        \n",
    "\n",
    "        for _id,y in enumerate(Y_data):\n",
    "            if y <= tow:\n",
    "                plot_y.append(y)\n",
    "                plot_x.append(X_data[_id])\n",
    "\n",
    "        \n",
    "        plot_data(plot_x,plot_y,plot_type='r-',X_name='Recall',Y_name='Precision')\n",
    "        return conf_matrix,np.trapz(plot_y,plot_x)\n",
    "\n",
    "    return conf_matrix,np.trapz(pr_details[class_id]['prec'],pr_details[class_id]['rec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_GDA(K,data_set,PR_Curve='N',tow=1):\n",
    "    '''\n",
    "    Construct the confusion matrix, and compute the performance measures such as:\n",
    "    1. Precision\n",
    "    2. Accuracy\n",
    "    3. Recall\n",
    "    4. F-Measure\n",
    "    '''\n",
    "    conf_matrix,AUC = K_fold(K,np.loadtxt(data_set),PR_Curve,tow)\n",
    "    perf_measures = evaluate_performance(conf_matrix)\n",
    "    \n",
    "    print 'Confusion Matrix : \\n' + str(conf_matrix) + '\\n'\n",
    "    print 'Accuracy : ' + '\\n' + str(perf_measures['acc'])\n",
    "    \n",
    "    #Precision,Recall and F-Measure :\n",
    "    for cls in perf_measures['rec'].keys():\n",
    "        print 'Precision of class '+ str(cls) + ' is : \\n' + str(perf_measures['prec'][cls])\n",
    "        print 'Recall of class '+ str(cls) + ' is : \\n' + str(perf_measures['rec'][cls])\n",
    "        print 'F-Measure of class '+ str(cls) + ' is : \\n' + str(perf_measures['F-Measure'][cls])\n",
    "        print ''\n",
    "    \n",
    "    return conf_matrix, perf_measures,'Area : ' + str(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###GDA on <font color = 'green'>1 Dimensional , 2 Class </font>Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[      0.       0.]\n",
      " [  50859.  194198.]]\n",
      "\n",
      "Accuracy : \n",
      "0.792460529591\n",
      "Precision of class 1 is : \n",
      "0.0\n",
      "Recall of class 1 is : \n",
      "0.0\n",
      "F-Measure of class 1 is : \n",
      "0.0\n",
      "\n",
      "Precision of class 2 is : \n",
      "0.792460529591\n",
      "Recall of class 2 is : \n",
      "1.0\n",
      "F-Measure of class 2 is : \n",
      "0.88421531912\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[      0.,       0.],\n",
       "        [  50859.,  194198.]]),\n",
       " defaultdict(<function <lambda> at 0x000000001A6B0668>, {'acc': 0.79246052959107471, 'rec': defaultdict(<function <lambda> at 0x000000001A6B0828>, {1: 0.0, 2: 1.0}), 'F-Measure': defaultdict(<function <lambda> at 0x000000001A6B0DD8>, {1: 0.0, 2: 0.88421531911987339}), 'prec': defaultdict(<function <lambda> at 0x000000001A6B0C88>, {1: 0.0, 2: 0.79246052959107471})}),\n",
       " 'Area : 9.83090837593e-06')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = perform_GDA(10,'Skin_NonSkin.txt','N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####As seen above , the accuracy of predictions is 79.24%, which is quite low. <br/>This is because, the orginial dataset contained 3 features, out which 2 were discarded and only 1 was chosen.<br/> Now lets try performing GDA on the original file with 3 features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###GDA on <font color = 'green'>n Dimensional , 2 Class </font>Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEPCAYAAAAJYmAlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad23630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[  37846.     295.]\n",
      " [  13013.  193903.]]\n",
      "\n",
      "Accuracy : \n",
      "0.945694267048\n",
      "Precision of class 1 is : \n",
      "0.992265541019\n",
      "Recall of class 1 is : \n",
      "0.744135747852\n",
      "F-Measure of class 1 is : \n",
      "0.850471910112\n",
      "\n",
      "Precision of class 2 is : \n",
      "0.937109745017\n",
      "Recall of class 2 is : \n",
      "0.998480931832\n",
      "F-Measure of class 2 is : \n",
      "0.966822399617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = perform_GDA(10,'Skin_NonSkin_full.txt','Y',0.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####As seen above, the accuracy has risen to 94.5% after including all the features <br/>Now lets perform GDA on a n Dimensional , k Class Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###GDA on <font color = 'green'>n Dimensional , k Class </font>Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[ 50.   0.   0.]\n",
      " [  0.  46.   1.]\n",
      " [  0.   4.  49.]]\n",
      "\n",
      "Accuracy : \n",
      "0.966666666667\n",
      "Precision of class 1 is : \n",
      "1.0\n",
      "Recall of class 1 is : \n",
      "1.0\n",
      "F-Measure of class 1 is : \n",
      "1.0\n",
      "\n",
      "Precision of class 2 is : \n",
      "0.978723404255\n",
      "Recall of class 2 is : \n",
      "0.92\n",
      "F-Measure of class 2 is : \n",
      "0.948453608247\n",
      "\n",
      "Precision of class 3 is : \n",
      "0.924528301887\n",
      "Recall of class 3 is : \n",
      "0.98\n",
      "F-Measure of class 3 is : \n",
      "0.95145631068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = perform_GDA(10,'iris.data','N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Naive Bayes with Bernoulli Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beta_c(labels):\n",
    "    '''Compute and Return prior probabilities for different classes in the dataset'''\n",
    "    total_examples = len(labels)\n",
    "\n",
    "    prior_probs = defaultdict(lambda : 0.0)\n",
    "\n",
    "    for x in labels:\n",
    "        prior_probs[x[0]] += 1\n",
    "\n",
    "    for k in prior_probs.keys():\n",
    "        prior_probs[k] = float(prior_probs[k])/total_examples\n",
    "\n",
    "    return prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alphas(features,labels,e):\n",
    "    '''Returns the computed alphas dictionary of form alpha[col][class]'''\n",
    "    cls_and_count = defaultdict(lambda : 0)\n",
    "    \n",
    "    for x in labels:\n",
    "        cls_and_count[x[0]] += 1\n",
    "    \n",
    "    alphas = defaultdict(lambda : defaultdict(lambda : 0.0))\n",
    "    \n",
    "    total_cols = features.shape[1]\n",
    "    \n",
    "    for col_id in range(0,total_cols):\n",
    "        \n",
    "        cur_col = features[:,col_id:col_id + 1]\n",
    "        \n",
    "        for r_id,value in enumerate(cur_col):\n",
    "            \n",
    "            cls_label = labels[r_id][0]\n",
    "                        \n",
    "            if value == 1:                                                \n",
    "                alphas[col_id][cls_label] += 1\n",
    "            else:\n",
    "                alphas[col_id][cls_label] #just a default zero initialization\n",
    "    \n",
    "    \n",
    "    for col_id in range(0,total_cols):\n",
    "        for cls_label in cls_and_count.keys():            \n",
    "            alphas[col_id][cls_label] = float(alphas[col_id][cls_label] + e) / (cls_and_count[cls_label] + (2*e))\n",
    "    \n",
    "    return alphas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function <lambda> at 0x000000001A691128>, {0: defaultdict(<function <lambda> at 0x000000001A691198>, {0.0: 0.045454545454545456, 1.0: 0.96875}), 1: defaultdict(<function <lambda> at 0x000000001A691D68>, {0.0: 0.5, 1.0: 0.65625}), 2: defaultdict(<function <lambda> at 0x000000001A6910B8>, {0.0: 0.9545454545454545, 1.0: 0.96875})})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas(tst_features,tst_labels,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nb_bern_membership(vec_to_be_pred,alphas,beta_c):\n",
    "    \n",
    "    \n",
    "    prev_mem = -maxint-1\n",
    "    best_class = -1\n",
    "    \n",
    "    for cls in beta_c.keys():\n",
    "        \n",
    "        prob_sum = 0\n",
    "        \n",
    "        for j in range(0,len(vec_to_be_pred)):\n",
    "                    \n",
    "            \n",
    "            temp1 = vec_to_be_pred[j]* math.log(alphas[j][cls])\n",
    "            temp2 = (1-vec_to_be_pred[j]) * (math.log(1 - alphas[j][cls]))\n",
    "            \n",
    "            prob_sum += (temp1 + temp2) \n",
    "        \n",
    "        prob_sum += math.log(beta_c[cls])\n",
    "        \n",
    "        if prob_sum >= prev_mem:\n",
    "            prev_mem = prob_sum\n",
    "            best_class = cls\n",
    "    \n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data matrix\n",
    "def Bern_NB(file_name,delimiter):\n",
    "    ''''''\n",
    "    data_matrix = np.loadtxt(file_name,delimiter=',')\n",
    "\n",
    "    #segregate features and labels\n",
    "    features,labels = get_features_labels(data_matrix)\n",
    "        \n",
    "\n",
    "    #binarize features\n",
    "    binarizer = Binarizer(threshold=0.0)\n",
    "    bin_features = binarizer.transform(features)\n",
    "\n",
    "    betas = beta_c(labels)\n",
    "\n",
    "    alpha_scores = alphas(bin_features,labels,1)\n",
    "\n",
    "    pred_cls_lst = []\n",
    "    \n",
    "    for vec in bin_features:\n",
    "        pred_cls_lst.append(nb_bern_membership(vec,alpha_scores,betas))\n",
    "    \n",
    "    #confusion matrix\n",
    "    ls_lbls = []\n",
    "\n",
    "    for lbl in labels:\n",
    "        ls_lbls.append(lbl[0])\n",
    "\n",
    "    distinct_lbls = len(set(ls_lbls))\n",
    "    \n",
    "    conf_matrix = np.zeros((distinct_lbls,distinct_lbls))\n",
    "    \n",
    "    for _id,actual in enumerate(labels):\n",
    "        actual = int(actual)\n",
    "        pred = int(pred_cls_lst[_id])\n",
    "        \n",
    "        conf_matrix[pred-1,actual-1] += 1\n",
    "    \n",
    "    perf_measures = evaluate_performance(conf_matrix)\n",
    "    \n",
    "    print 'Confusion Matrix : \\n' + str(conf_matrix) + '\\n'\n",
    "    print 'Accuracy : ' + '\\n' + str(perf_measures['acc'])\n",
    "    \n",
    "    #Precision,Recall and F-Measure :\n",
    "    for cls in perf_measures['rec'].keys():\n",
    "        print 'Precision of class '+ str(cls) + ' is : \\n' + str(perf_measures['prec'][cls])\n",
    "        print 'Recall of class '+ str(cls) + ' is : \\n' + str(perf_measures['rec'][cls])\n",
    "        print 'F-Measure of class '+ str(cls) + ' is : \\n' + str(perf_measures['F-Measure'][cls])\n",
    "        print ''    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[ 1478.   190.]\n",
      " [  335.  2598.]]\n",
      "\n",
      "Accuracy : \n",
      "0.885894370789\n",
      "Precision of class 1 is : \n",
      "0.886091127098\n",
      "Recall of class 1 is : \n",
      "0.815223386652\n",
      "F-Measure of class 1 is : \n",
      "0.84918126975\n",
      "\n",
      "Precision of class 2 is : \n",
      "0.885782475281\n",
      "Recall of class 2 is : \n",
      "0.931850789096\n",
      "F-Measure of class 2 is : \n",
      "0.908232826429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bern_NB('spambase.data',',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Let's Compare the accuracy with sklearn's BernoulliNB package</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "def sk_Bern_NB_accuracy(file_name):\n",
    "    data_matrix = np.loadtxt(file_name,delimiter=',')\n",
    "\n",
    "    #segregate features and labels\n",
    "    features,labels = get_features_labels(data_matrix)\n",
    "\n",
    "    #binarize features\n",
    "    binarizer = Binarizer(threshold=0.0)\n",
    "    bin_features = binarizer.transform(features)\n",
    "\n",
    "\n",
    "    clf = BernoulliNB()\n",
    "    \n",
    "    clf.fit(bin_features, column_or_1d(labels, warn=False))\n",
    "\n",
    "    pred_ls = []\n",
    "    for vec in features:\n",
    "        pred_ls.append(clf.predict(vec))\n",
    "\n",
    "    ls_lbls = []\n",
    "\n",
    "    for lbl in labels:\n",
    "        ls_lbls.append(lbl[0])\n",
    "\n",
    "    pred_ls_lbls = []\n",
    "\n",
    "    for lbl in pred_ls:\n",
    "        pred_ls_lbls.append(lbl[0])\n",
    "\n",
    "    return accuracy_score(ls_lbls, pred_ls_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88589437078895894"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_Bern_NB_accuracy('spambase.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> In both cases, accuracy is found to be 88.5. Hence Verified. <br><br> The accuracy was so less i.e 88.58 % because, the features in the SPAM dataset were binarized during Bernoulli NB. </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Naive Bayes with Binomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alpha_binomial(features,doc_and_len,labels,e):\n",
    "    \n",
    "    class_and_sum = defaultdict(lambda : 0)\n",
    "    \n",
    "    for k,v in doc_and_len.items():\n",
    "        lbls = labels[k][0]\n",
    "        class_and_sum[lbls] += v\n",
    "    \n",
    "    \n",
    "    alphas = defaultdict(lambda : defaultdict(lambda : 0.0))\n",
    "    \n",
    "    total_cols = features.shape[1]\n",
    "    \n",
    "    for col_id in range(0,total_cols):\n",
    "        \n",
    "        cur_col = features[:,col_id:col_id + 1]\n",
    "        \n",
    "        for r_id,value in enumerate(cur_col):\n",
    "            \n",
    "            cls_label = labels[r_id][0]\n",
    "            \n",
    "            alphas[col_id][cls_label] += value\n",
    "            '''\n",
    "            if value == 1:                                                \n",
    "                alphas[col_id][cls_label] += value\n",
    "            else:\n",
    "                alphas[col_id][cls_label] #just a default zero initialization\n",
    "            '''\n",
    "    \n",
    "   \n",
    "    for col_id in range(0,total_cols):\n",
    "        for cls_label in class_and_sum.keys():            \n",
    "            alphas[col_id][cls_label] = float(alphas[col_id][cls_label] + e) / (class_and_sum[cls_label] + (2*e))\n",
    "    \n",
    "    return alphas\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_binomial_membership(vec_to_be_pred,alphas,beta_c):\n",
    "    \n",
    "    \n",
    "    prev_mem = -maxint-1\n",
    "    best_class = -1\n",
    "    \n",
    "    for cls in beta_c.keys():\n",
    "        \n",
    "        prob_sum = 0\n",
    "        \n",
    "        for j in range(0,len(vec_to_be_pred)):\n",
    "            \n",
    "            p = sum(vec_to_be_pred)\n",
    "            xj = vec_to_be_pred[j]\n",
    "            \n",
    "            temp1 = comb(p,xj)\n",
    "            temp2 = math.pow(alphas[j][cls],xj)\n",
    "            temp3 = math.pow(1 - alphas[j][cls],(p-xj))\n",
    "            \n",
    "\n",
    "            part1 = math.log(temp1) +math.log(temp2)  +math.log(temp3)\n",
    "            \n",
    "            prob_sum += part1\n",
    "        \n",
    "        prob_sum += math.log(beta_c[cls])\n",
    "        \n",
    "        if prob_sum >= prev_mem:\n",
    "            prev_mem = prob_sum\n",
    "            best_class = cls\n",
    "    \n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#randomly assign a doc_len\n",
    "def Binomial(data_set):\n",
    "    data_matrix = np.loadtxt(data_set,delimiter=',')\n",
    "\n",
    "    features,labels = get_features_labels(data_matrix)\n",
    "\n",
    "    #Extract first 48 features\n",
    "    features = features[:,:48]\n",
    "\n",
    "    doc_and_len = defaultdict(int)\n",
    "\n",
    "    for r_id,vec in enumerate(features):\n",
    "\n",
    "        doc_len = 10\n",
    "        doc_and_len[r_id] = doc_len\n",
    "\n",
    "        for c_id,cell in enumerate(vec):            \n",
    "            features[r_id,c_id] = int(cell * doc_len) \n",
    "\n",
    "    #Prior class probs\n",
    "    betas = beta_c(labels)\n",
    "\n",
    "\n",
    "    #start\n",
    "    alpha_scores = alpha_binomial(features,doc_and_len,labels,1)\n",
    "\n",
    "    pred_cls_lst = []\n",
    "    for vec in features:\n",
    "        pred_cls_lst.append(nb_binomial_membership(vec,alpha_scores,betas))\n",
    "\n",
    "    #confusion matrix\n",
    "    ls_lbls = []\n",
    "\n",
    "    for lbl in labels:\n",
    "        ls_lbls.append(lbl[0])\n",
    "\n",
    "    distinct_lbls = len(set(ls_lbls))\n",
    "\n",
    "    conf_matrix = np.zeros((distinct_lbls,distinct_lbls))\n",
    "\n",
    "    for _id,actual in enumerate(labels):\n",
    "        actual = int(actual)\n",
    "        pred = int(pred_cls_lst[_id])\n",
    "\n",
    "        conf_matrix[pred-1,actual-1] += 1\n",
    "\n",
    "    perf_measures = evaluate_performance(conf_matrix)\n",
    "\n",
    "    print 'Confusion Matrix : \\n' + str(conf_matrix) + '\\n'\n",
    "    print 'Accuracy : ' + '\\n' + str(perf_measures['acc'])\n",
    "\n",
    "    #Precision,Recall and F-Measure :\n",
    "    for cls in perf_measures['rec'].keys():\n",
    "        print 'Precision of class '+ str(cls) + ' is : \\n' + str(perf_measures['prec'][cls])\n",
    "        print 'Recall of class '+ str(cls) + ' is : \\n' + str(perf_measures['rec'][cls])\n",
    "        print 'F-Measure of class '+ str(cls) + ' is : \\n' + str(perf_measures['F-Measure'][cls])\n",
    "        print '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[ 1736.  2182.]\n",
      " [   77.   606.]]\n",
      "\n",
      "Accuracy : \n",
      "0.509019778309\n",
      "Precision of class 1 is : \n",
      "0.443083205717\n",
      "Recall of class 1 is : \n",
      "0.957528957529\n",
      "F-Measure of class 1 is : \n",
      "0.605827953237\n",
      "\n",
      "Precision of class 2 is : \n",
      "0.887262079063\n",
      "Recall of class 2 is : \n",
      "0.217360114778\n",
      "F-Measure of class 2 is : \n",
      "0.349178910977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Binomial('spambase.data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
